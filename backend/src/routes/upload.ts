import { Router } from 'express';
import { v4 as uuidv4 } from 'uuid';
import { PDFParser } from '../services/pdfParser';
import { VectorStore } from '../services/vectorStore';
import { MatchingService } from '../services/matchingService';
import { UploadResponse } from '../types';

const router = Router();
const pdfParser = new PDFParser();
const vectorStore = new VectorStore();
const matchingService = new MatchingService();

router.post('/', async (req, res) => {
  try {
    console.log('\nüì§ === NEW UPLOAD REQUEST ===');
    
    if (!req.files || !req.files.resume || !req.files.jobDescription) {
      console.log('‚ùå Missing files');
      return res.status(400).json({ error: 'Both resume and job description are required' });
    }

    const resumeFile = Array.isArray(req.files.resume) ? req.files.resume[0] : req.files.resume;
    const jdFile = Array.isArray(req.files.jobDescription) 
      ? req.files.jobDescription[0] 
      : req.files.jobDescription;

    console.log(`üìÑ Resume: ${resumeFile.name} (${(resumeFile.size / 1024).toFixed(2)} KB)`);
    console.log(`üìã Job Description: ${jdFile.name} (${(jdFile.size / 1024).toFixed(2)} KB)`);

    // Generate session ID
    const sessionId = uuidv4();
    console.log(`üîë Session ID: ${sessionId}`);

    // Extract text from files (PDF or TXT)
    console.log('\nüìñ Extracting text from files...');
    const resumeText = await pdfParser.extractText(resumeFile.data, resumeFile.name);
    const jdText = await pdfParser.extractText(jdFile.data, jdFile.name);
    console.log(`‚úì Resume text: ${resumeText.length} characters`);
    console.log(`‚úì Job description text: ${jdText.length} characters`);

    // Chunk documents
    console.log('\n‚úÇÔ∏è  Chunking documents...');
    const resumeChunks = pdfParser.chunkText(resumeText, 'resume');
    const jdChunks = pdfParser.chunkText(jdText, 'jobDescription');
    console.log(`‚úì Resume chunks: ${resumeChunks.length}`);
    console.log(`‚úì Job description chunks: ${jdChunks.length}`);

    // Store in vector database (RAG implementation)
    console.log('\nüîÆ Generating embeddings and storing in Pinecone...');
    await Promise.all([
      vectorStore.storeChunks(sessionId, resumeChunks, 'resume'),
      vectorStore.storeChunks(sessionId, jdChunks, 'jobDescription'),
    ]);
    console.log(`‚úì Stored ${resumeChunks.length + jdChunks.length} vectors in Pinecone`);

    // Analyze match
    console.log('\nü§ñ Analyzing match with AI...');
    const analysis = await matchingService.analyzeMatch(resumeText, jdText);
    console.log(`‚úì Match score: ${analysis.score}%`);

    const response: UploadResponse = {
      sessionId,
      matchScore: analysis.score,
      strengths: analysis.strengths,
      gaps: analysis.gaps,
      insights: analysis.insights,
    };

    console.log('\n‚úÖ Upload complete!\n');
    res.json(response);
  } catch (error) {
    console.error('\n‚ùå Upload error:', error);
    res.status(500).json({ error: 'Failed to process files' });
  }
});

export default router;
