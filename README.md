# ğŸ¤– AI-Powered Resume Screening Tool

> A production-ready RAG (Retrieval-Augmented Generation) system for intelligent resume analysis and candidate Q&A

[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=flat&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![React](https://img.shields.io/badge/React-20232A?style=flat&logo=react&logoColor=61DAFB)](https://reactjs.org/)
[![Node.js](https://img.shields.io/badge/Node.js-43853D?style=flat&logo=node.js&logoColor=white)](https://nodejs.org/)
[![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=flat&logo=openai&logoColor=white)](https://openai.com/)
[![Pinecone](https://img.shields.io/badge/Pinecone-000000?style=flat&logo=pinecone&logoColor=white)](https://www.pinecone.io/)

## ï¿½ Tablre of Contents

- [Overview](#overview)
- [Features](#features)
- [Tech Stack](#tech-stack)
- [RAG Architecture](#rag-architecture)
- [Quick Start](#quick-start)
- [Usage](#usage)
- [API Documentation](#api-documentation)
- [Testing](#testing)
- [Project Structure](#project-structure)
- [Contributing](#contributing)

## ğŸ¯ Overview

This application revolutionizes the resume screening process by combining AI-powered analysis with semantic search capabilities. Built with a true RAG architecture, it provides accurate, context-aware insights about candidates by intelligently retrieving relevant information from resumes and generating precise answers.

### Why RAG?

Traditional approaches send entire resumes to LLMs, which is:
- âŒ Expensive (high token usage)
- âŒ Slow (processing large documents)
- âŒ Less accurate (information gets lost in context)

Our RAG approach:
- âœ… Cost-effective (only relevant chunks processed)
- âœ… Fast (semantic search in milliseconds)
- âœ… Accurate (focused context for each question)
- âœ… Scalable (handles thousands of resumes)

## âœ¨ Features

### ğŸ“¤ Smart Document Upload
- Support for PDF and TXT formats
- Automatic text extraction and parsing
- Intelligent document chunking by sections
- Real-time processing feedback

### ğŸ¯ AI-Powered Match Analysis
- **Match Score (0-100%)**: Accurate scoring based on job requirements
- **Strengths Identification**: Highlights candidate's best qualifications
- **Gap Analysis**: Identifies missing skills or experience
- **Key Insights**: AI-generated summary of candidate fit

### ğŸ’¬ RAG-Powered Chat Interface
- Ask natural language questions about candidates
- Context-aware responses with source attribution
- Semantic search retrieves relevant resume sections
- Distinguishes between different role types (DevOps vs Backend, etc.)

### ğŸ¨ Professional UI
- Modern, responsive design
- Real-time loading states
- Gradient animations and smooth transitions
- Mobile-friendly interface

## ğŸ› ï¸ Tech Stack

### Backend
| Technology | Purpose | Version |
|------------|---------|---------|
| **Node.js** | Runtime environment | 18+ |
| **TypeScript** | Type safety | 5.x |
| **Express.js** | Web framework | 4.x |
| **OpenAI API** | Embeddings & LLM | Latest |
| **Pinecone** | Vector database | 2.x |
| **pdf-parse** | PDF extraction | 1.x |

### Frontend
| Technology | Purpose | Version |
|------------|---------|---------|
| **React** | UI framework | 18.x |
| **TypeScript** | Type safety | 5.x |
| **Vite** | Build tool | 5.x |
| **Tailwind CSS** | Styling | 3.x |
| **Axios** | HTTP client | 1.x |

## ğŸ—ï¸ RAG Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     UPLOAD FLOW                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Resume PDF/TXT                                             â”‚
â”‚       â†“                                                     â”‚
â”‚  Extract Text (pdf-parse)                                   â”‚
â”‚       â†“                                                     â”‚
â”‚  Chunk by Sections (Experience, Education, Skills, etc.)    â”‚
â”‚       â†“                                                     â”‚
â”‚  Generate Embeddings (OpenAI text-embedding-3-small)        â”‚
â”‚       â†“                                                     â”‚
â”‚  Store Vectors in Pinecone (1024 dimensions)                â”‚
â”‚       â†“                                                     â”‚
â”‚  Analyze Match with LLM (GPT-3.5-turbo)                     â”‚
â”‚       â†“                                                     â”‚
â”‚  Return Score, Strengths, Gaps, Insights                    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CHAT FLOW (RAG)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  User Question: "Does candidate have React experience?"     â”‚
â”‚       â†“                                                     â”‚
â”‚  Generate Question Embedding                                â”‚
â”‚       â†“                                                     â”‚
â”‚  Semantic Search in Pinecone (cosine similarity)            â”‚
â”‚       â†“                                                     â”‚
â”‚  Retrieve Top 4 Relevant Chunks                             â”‚
â”‚       â†“                                                     â”‚
â”‚  Build Augmented Prompt: [Context] + [Question]             â”‚
â”‚       â†“                                                     â”‚
â”‚  LLM Generates Answer (GPT-3.5-turbo)                       â”‚
â”‚       â†“                                                     â”‚
â”‚  Return Answer + Sources                                    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

1. **Document Processing**: Extracts text and chunks into semantic sections
2. **Embedding Generation**: Converts text to 1024-dimensional vectors
3. **Vector Storage**: Stores embeddings in Pinecone with metadata
4. **Semantic Search**: Finds relevant chunks using cosine similarity
5. **Context Augmentation**: Combines retrieved chunks with user question
6. **Answer Generation**: LLM generates accurate, context-aware responses

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18 or higher
- npm or yarn
- OpenAI API key (OpenRouter)
- Pinecone account (free tier available)

### 1. Clone Repository

```bash
git clone https://github.com/yourusername/resume-screening-rag.git
cd resume-screening-rag
```

### 2. Setup Pinecone

1. Sign up at [pinecone.io](https://www.pinecone.io/)
2. Create a new index:
   - **Name**: `resume-screening`
   - **Dimensions**: `1024`
   - **Metric**: `cosine`
   - **Cloud**: AWS
   - **Region**: `us-east-1`

### 3. Configure Backend

```bash
cd backend
npm install
```

Create `.env` file:
```env
# OpenAI Configuration (OpenRouter)
OPENAI_API_KEY=your-openrouter-api-key

# Pinecone Configuration
PINECONE_API_KEY=your-pinecone-api-key
PINECONE_ENVIRONMENT=us-east-1-aws
PINECONE_INDEX_NAME=resume-screening

# Server Configuration
PORT=3001
NODE_ENV=development
FRONTEND_URL=http://localhost:5173
```

Start backend:
```bash
npm run dev
```

Backend will run on: **http://localhost:3001**

### 4. Setup Frontend

Open new terminal:

```bash
cd frontend
npm install
npm run dev
```

Frontend will run on: **http://localhost:5173**

### 5. Test the Application

1. Open http://localhost:5173 in your browser
2. Upload sample files from `sample-data/` folder:
   - Resume: `resume1.txt`
   - Job Description: `job-description.txt`
3. Click "Analyze Resume"
4. View match analysis
5. Ask questions in the chat!

## ğŸ“– Usage

### Uploading Documents

1. Click "Choose File" for Resume
2. Select a PDF or TXT file (max 10MB)
3. Click "Choose File" for Job Description
4. Select a PDF or TXT file
5. Click "Analyze Resume"
6. Wait 5-10 seconds for processing

### Viewing Match Analysis

The system displays:
- **Match Score**: 0-100% based on job requirements
- **Strengths**: Top qualifications that match the role
- **Gaps**: Missing skills or experience
- **Key Insights**: AI-generated summary

### Asking Questions

Try these example questions:

**Yes/No Questions:**
- "Does this candidate have a degree from a state university?"
- "Do they have AWS certifications?"
- "Can they lead a backend team?"

**Specific Information:**
- "How many years of React experience do they have?"
- "What companies have they worked for?"
- "What's their education background?"

**Analytical Questions:**
- "What are their main technical strengths?"
- "What leadership experience do they have?"

## ğŸ“¡ API Documentation

### Health Check

```http
GET /health
```

**Response:**
```json
{
  "status": "ok"
}
```

### Upload Documents

```http
POST /api/upload
Content-Type: multipart/form-data
```

**Request:**
- `resume`: File (PDF/TXT)
- `jobDescription`: File (PDF/TXT)

**Response:**
```json
{
  "sessionId": "550e8400-e29b-41d4-a716-446655440000",
  "matchScore": 75,
  "strengths": [
    "5+ years of Node.js and React experience",
    "Strong backend architecture skills",
    "Experience with PostgreSQL"
  ],
  "gaps": [
    "No Kubernetes experience",
    "Limited AWS cloud experience"
  ],
  "insights": "Strong candidate with solid full-stack experience..."
}
```

### Ask Question

```http
POST /api/chat
Content-Type: application/json
```

**Request:**
```json
{
  "sessionId": "550e8400-e29b-41d4-a716-446655440000",
  "question": "Does this candidate have React experience?"
}
```

**Response:**
```json
{
  "answer": "Yes, the candidate has 5 years of React experience, working with Redux and TypeScript in production environments.",
  "sources": ["experience", "skills"]
}
```

## ğŸ§ª Testing

### Sample Data

The project includes 4 sample files in `sample-data/`:

1. **resume1.txt** - Full Stack Developer (5 years)
2. **resume2.txt** - Senior Cloud Engineer (6 years)
3. **resume3.txt** - Junior Developer (3 years)
4. **job-description.txt** - Backend Developer role
5. **cloud-engineer-job.txt** - Cloud Engineer role
6. **cloud-engineer-resume.txt** - Cloud Engineer candidate

### Test Scenarios

See [TESTING_SCENARIOS.md](./TESTING_SCENARIOS.md) for detailed test cases.

### Verifying RAG Implementation

Check backend logs for:
```
ğŸ”® Generating embeddings and storing in Pinecone...
âœ“ Stored 8 vectors in Pinecone
ğŸ” Searching vectors in Pinecone...
âœ“ Found 4 matches
```

## ğŸ“ Project Structure

```
resume-screening-rag/
â”œâ”€â”€ backend/                    # Node.js backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ config/            # Configuration (OpenAI)
â”‚   â”‚   â”œâ”€â”€ services/          # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ pdfParser.ts   # PDF extraction & chunking
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddingService.ts  # Generate embeddings
â”‚   â”‚   â”‚   â”œâ”€â”€ vectorStore.ts # Pinecone operations
â”‚   â”‚   â”‚   â”œâ”€â”€ ragService.ts  # RAG implementation
â”‚   â”‚   â”‚   â””â”€â”€ matchingService.ts   # Match scoring
â”‚   â”‚   â”œâ”€â”€ routes/            # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ upload.ts      # File upload
â”‚   â”‚   â”‚   â””â”€â”€ chat.ts        # Chat Q&A
â”‚   â”‚   â”œâ”€â”€ types/             # TypeScript types
â”‚   â”‚   â””â”€â”€ server.ts          # Express app
â”‚   â”œâ”€â”€ .env                   # Environment variables
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ frontend/                   # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ FileUpload.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ MatchAnalysis.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ChatInterface.tsx
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts         # API client
â”‚   â”‚   â”œâ”€â”€ App.tsx            # Main app
â”‚   â”‚   â””â”€â”€ main.tsx           # Entry point
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ sample-data/               # Test files
â”œâ”€â”€ ARCHITECTURE.md            # System design
â”œâ”€â”€ TESTING_SCENARIOS.md       # Test cases
â””â”€â”€ README.md                  # This file
```

## ğŸ¯ Key Features Explained

### 1. True RAG Implementation

This is NOT just sending resumes to an LLM. It's a proper RAG system:

- âœ… **Vector Embeddings**: Converts text to numerical vectors
- âœ… **Semantic Search**: Finds relevant content by meaning, not keywords
- âœ… **Context Retrieval**: Only sends relevant chunks to LLM
- âœ… **Source Attribution**: Shows which resume sections were used

### 2. Intelligent Chunking

Documents are split intelligently:
- **Resumes**: By sections (Experience, Education, Skills, etc.)
- **Job Descriptions**: By requirements and paragraphs
- **Overlap**: 50 tokens between chunks for context continuity

### 3. Accurate Scoring

Match scores are based on:
- Skills match (40%)
- Experience match (30%)
- Education match (20%)
- Keywords match (10%)

### 4. Role-Aware Responses

The AI understands role distinctions:
- DevOps Engineer â‰  Backend Developer
- Leading DevOps team â‰  Leading Backend Dev team
- Infrastructure experience â‰  Application development

## ğŸ”’ Security

- API keys stored in environment variables
- File size limits (10MB)
- Input validation and sanitization
- CORS configuration
- Session-based data isolation

## ğŸ“Š Performance

| Operation | Time | Details |
|-----------|------|---------|
| Upload & Analysis | 5-10s | PDF parse â†’ Chunk â†’ Embed â†’ Store â†’ Analyze |
| Chat Response | 2-3s | Embed query â†’ Search â†’ Generate |
| Vector Search | <100ms | Pinecone semantic search |

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ‘¥ Authors

Built for JobTalk.ai Backend Developer Assessment

## ğŸ“ Support

For questions or issues, please contact: aaryanacharya12003@gmail.com

---

**Built with â¤ï¸ using OpenAI, Pinecone, React, and Node.js**
